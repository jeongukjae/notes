---
layout: post
title: "2019 머신러닝 스터디잼 입문반"
tags:
  - studyjam
---

이전에 진행했던 Kubernetes를 주제로한 스터디잼에 이어서 [ML 스터디잼 입문반](https://sites.google.com/view/ml-studyjam/)에도 참여해보았다. 처음 참여했던 것과 다르게 그룹장으로 참여하게 되었고, 진행방식도 조금은 달라진 것을 알 수 있었다. 클라우드 스터디잼은 하나의 퀘스트를 완수하는 것이 목표였지만, ML 스터디잼은 주어진 랩 4개를 완수하는 것이 목표였다. 퀘스트를 완수하면 뱃지가 주어지기 때문에 바로 "다 완수했구나!"를 알 수 있었지만, 랩 몇몇개를 찾아서 완수하는 방식은 "정말 다 끝냈나..?"라고 확인하면서 괜히 한번 더 확인해보게 되었다.

## 여튼 내용 정리

어찌되었든 내용을 정리해보자면, 역시 GCP를 기반으로 몇몇 ML 관련 API를 사용해보는 것이 목표였다. 진행한 랩들의 제목은 아래와 같다.

* Google Cloud Speech API: Qwik Start
* Cloud Natural Language API: Qwik Start
* Speech to Text Transcription with the Cloud Speech API
* Entity and Sentiment Analysis with the Natural Language API

전체적으로 이론의 이해를 크게 필요로 하지 않는 쉬운 난이도의 랩들이었고, 그 때문에 새로 알게된 내용 자체도 적었다. 물론 소요된 시간도 4개의 랩을 합쳐 1시간 정도였다. 미리 퀵랩을 사용해보았고, GCP 또한 대충은 사용해보았고, 클라우드 스터디잼에서 거의 매 랩마다 생성하던 클러스터 생성같은 오래 걸리는 과정도 없어서 정말 빨리 끝났다. 그래도 하나씩 간략한 내용을 정리해보려 한다.

## 1. Google Cloud Speech API: Qwik Start

[Google Cloud Speech API](https://cloud.google.com/speech-to-text/docs/)를 활용해보는 랩이다. 해당 API는 speech recognition과 관련된 API이며, 오디오를 보내면 해당 오디오에 해당하는 text transcription을 보내주는 API이다.

Google Cloud Speech API는 사용하기 위해서 API KEY가 필요하다. 이를 발급받은 후, 오디오를 API로 전송하는데, 실습 예제에서는 인코딩 형태, 언어등의 정보들을 담고, 오디오 파일의 `uri`를 `json`파일 형태로 담아 전송하였다.

```bash
$ cat request.json
{
  "config": {
      "encoding":"FLAC",
      "sample_rate": 16000,
      "language_code": "en-US"
  },
  "audio": {
      "uri":"gs://{오디오 파일 uri}"
  }
}
$ curl -s -X POST -H "Content-Type: application/json" --data-binary @request.json \
"https://speech.googleapis.com/v1beta1/speech:syncrecognize?key=${API_KEY}"
{
  "results": [
    {
      "alternatives": [
        {
          "transcript": "how old is the Brooklyn Bridge",
          "confidence": 0.98267895
        }
      ]
    }
  ]
}
```

위와 같은 형태로 전송하였다.

## 2. Cloud Natural Language API: Qwik Start

이 랩은 Cloud Natural Language API를 사용해보는 랩이었고, Syntax Analysis, Entity Recognition, Sentiment Analysis, Content Classification, Multi-Language 같은 기능이 있다고 소개한다. 그러한 기능들을 이용해 `analyze-entities`(사람이나, 장소, 이벤트같은 entity를 추출해내는 method)를 사용해보는 랩이다. 사실 아래의 API 호출 한번으로 끝나는 랩이다...

```bash
$ gcloud ml language analyze-entities --content="Michelangelo Caravaggio, Italian painter, is known for 'The Calling of Saint Matthew'."
{
  "entities": [
    {
      "name": "Michelangelo Caravaggio",
      "type": "PERSON",
      "metadata": {
        "wikipedia_url": "http://en.wikipedia.org/wiki/Caravaggio",
        "mid": "/m/020bg"
      },
      "salience": 0.83047235,
      "mentions": [
        {
          "text": {
            "content": "Michelangelo Caravaggio",
            "beginOffset": 0
          },
          "type": "PROPER"
        },
        {
          "text": {
            "content": "painter",
            "beginOffset": 33
          },
          "type": "COMMON"
        }
      ]
    },
    .....
    .....
  ],
  "language": "en"
}
```

## 3. Speech to Text Transcription with the Cloud Speech API

이건 사실 [1](#1-google-cloud-speech-api-qwik-start)과 호출하는 메소드는 다르지만, 거의 같은 방식의 사용법을 보여주기 때문에 따라만 하고 정리는 하지 않았다. 단지 여러가지 언어에 대해서 (80개 정도의 언어) 실행이 가능하다는 점만 달랐다.

## 4. Entity and Sentiment Analysis with the Natural Language API

해당 랩은 Cloud Natural Language API에서 텍스트로부터 entity를 추출해내고([2](#2-cloud-natural-language-api-qwik-start)와 비슷하다.), sentiment, syntactic analysis 등과 텍스트를 특정한 카테고리로 분류하는 작업을 진행한다고 한다. sentiment, syntactic analysis에 대해 정확히 아는 것이 아니라 어떤 것인지에 대해 랩을 진행한 후 간략히 찾아보았다.

일단 랩의 내용은 1, 2, 3을 진행하고 난 후에 보면 그렇게 새로 배우는 내용은 많지 않았다. 역시 API 사용법에 대한 랩이었고, 아래와 같이 내용을 배운다고 Overview에 적혀있었다.

* Creating a Natural Language API request and calling the API with curl
* Extracting entities and running sentiment analysis on text with the Natural Language API
* Performing linguistic analysis on text with the Natural Language API
* Creating a Natural Language API request in a different language

진행하면서 특별하게 신기한 내용은 없었기 때문에 따로 정리는 하지 않는다.

### sentiment & syntactic analysis

구글 Natural Language API 문서의 [Natural Language API - Concepts - Natural Language Basics](https://cloud.google.com/natural-language/docs/basics)에 간략하게 설명되어 있다.

> **Sentiment analysis** inspects the given text and identifies the prevailing emotional opinion within the text, especially to determine a writer's attitude as positive, negative, or neutral. Sentiment analysis is performed through the `analyzeSentiment` method.

그냥 말 그대로 주어진 텍스트에 대해 neutral한지, positive한지, negative한지 알려주는.. 그런 작업이다.

> **Syntactic analysis** extracts linguistic information, breaking up the given text into a series of sentences and tokens (generally, word boundaries), providing further analysis on those tokens. Syntactic Analysis is performed with the `analyzeSyntax` method.

이것도 말 그대로 문법에 대해 분석한 정보를 알려준다고 한다..

## 끝나고

저번 스터디잼과 다르게 굉장히 편한 마음으로 진행했다. 클라우드 스터디잼은 생각외로 입문반이라는 생각이 안들정도로 열심히 했던 것 같은데, ML 스터디잼은 쿠폰 받고, 1시간 내외로 전부 완료했으니 말이다. 그래도 한번쯤 개인 프로젝트에 사용할 수 있을만한 API들을 살펴보는 느낌으로 본다면 분명 나쁘지 않은 스터디잼이다. 조금 더 어려워도 좋을 것 같은 느낌이긴 하지만, 머신러닝에 대해서 겁내지 않고 시도해보기에 좋았던 것 같다.
