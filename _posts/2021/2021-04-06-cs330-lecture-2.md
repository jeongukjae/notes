---
layout: post
title: CS330 Lecture 2 Multi-Task & Meta-Learning Basics
tags:
  - cs330
---

2강이고 Multi-Task & Meta-Learning Basics이다.

* 강의 사이트 <http://cs330.stanford.edu/>
* 강의 비디오 <https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5>
* [2강 pdf](http://cs330.stanford.edu/slides/cs330_multitask_transfer_2020.pdf)

---

## Multitask learning

### Model

* MultiTask Learning objective: $$\min_\theta \sum^T_{i=1}\mathscr{L}_i(\theta, \mathscr{D}_i) $$ (Loss: $$\mathscr{L}$$, Dataset: $$\mathscr{D}$$)
* 가장 쉽게 multitask를 하는 방법: 여러 Expert Model을 만든 다음 태스크 종류에 따라서 사용한다. -> No Shared Parameters.
* 또 다른 방법: Classifier에 태스크 인덱스를 피쳐로 넣어준다.
  * 의견: one-hot vector로 넣어준다는 느낌인 것 같은데 학습이 잘 될까? 다른 classifier를 쓰는 편이 좋아보이는데
* 또 다른 방법들
  * Multi-head classification -> 일반적으로 내가 알고 있는 Multi-task learning. MT-DNN을 생각하면 된다.
  * Input vector에 태스크의 임베딩을 곱해주어서 분류하는 방법 (multiplicative gating)
    * Multiplicative conditioning은 네트워크와 head들을 전부 한꺼번에 generalize한다.
    * 의견: 하지만 적용할 부분을 찾기가 힘들어 보인다. 비슷한 종류의 분류를 해야하고, 레이블 갯수가 같아야하며, 태스크 간의 레이블이 각각 상관관계가 있어야 하는 것처럼 보인다.
* Conditioning 방법을 고르는 법
  * Problem Dependent
  * Largely guided by intuition or knowledge of the problem
  * currently more of an art than a science

### objective

* Vanilla MTL Objective가 잘 동작하긴 하는데, weighted sum을 쓸때도 많다. $$\min_\theta \sum^T_{i=1}w_i\mathscr{L}_i(\theta, \mathscr{D}_i)$$
  * -> 나도 이 방법을 더 많이 씀
* weighting하는 방법은 여러가지가 있는데 아래정도
  * various heuristics (Chen et al. GradNorm. ICML 2018)
  * use task uncertainty (see Kendall et al. CVPR 2018) <https://arxiv.org/abs/1705.07115>
    * 간단히 살펴봤는데 이게 일반적인 경우에 좋아보인다.
  * optimize for the worst-case task loss for fairness and robustness

### optimization

* 별다른 내용은 없고, task들이 uniform하게 잘 뽑히는지 살펴보면 좋다고
* regression 문제일 경우 같은 스케일인지 체크하자.

## Common Challenges in MTL

* **Negative transfer**: if independent networks work the best
  * Maybe optimization problem.
    * caused by cross-task interference.
    * Tasks may learn at different rates.
  * maybe representational capacity
    * MT networks often need to be much larger than single-task model
  * if nagative transfer problem occurs, share less parameters.
* **Overfitting**
  * Share more paraemters

## Case study

* Recommending What Video to Watch Next: A Multitask Ranking System
  * Recommendataion systems of Youtube
  * conflicting objectives
    * videos that users will rate highly
    * videos that users will share
    * videos that users will watch
    * 위 셋중 어떤걸 추천해야하나
  * implicit bias caused by feedback: 모델의 추천 결과가 유저 행동에 영향을 미치므로, 부정적인 피드백이 될 수도 있다.
  * 자세한 내용은 논문을 읽자

## MTL vs Transfer Learning

슬라이드에는 Transfer Learning과의 비교가 존재. 비디오에는 meta learning과의 비교가 존재

* MTL: Solve multiple tasks at once
* Transfer Learning: Solve target tasks after solving source task by transferring knowledge learned from source task.
  * Key assumption: Cannot acces source task dataset during transfer
* Transfer learning is a valid solution to MTL (not vice versa)
